{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jroethle/anaconda/envs/kaggle-ncaa/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import csv\n",
    "import random\n",
    "from sklearn import cross_validation, linear_model, model_selection\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "folder = 'input'\n",
    "season_data = pd.read_csv(folder + '/RegularSeasonDetailedResults.csv')\n",
    "tourney_data = pd.read_csv(folder + '/NCAATourneyDetailedResults.csv')\n",
    "ratings = pd.read_csv(folder + '/MasseyOrdinals_thruSeason2018_Day128.csv')\n",
    "seeds = pd.read_csv(folder + '/NCAATourneySeeds.csv')\n",
    "frames = [season_data, tourney_data]\n",
    "all_data = pd.concat(frames)\n",
    "stat_fields = ['score', 'fga', 'fgp', 'fga3', '3pp', 'ftp', 'or', 'dr',\n",
    "                   'ast', 'to', 'stl', 'blk', 'pf']\n",
    "stat_ratings = ['POM']\n",
    "ratings = ratings[ratings['SystemName'].isin(stat_ratings)]\n",
    "prediction_year = 2018\n",
    "base_elo = 1600\n",
    "BASE_ELO = 1500\n",
    "K = 20.\n",
    "HOME_ADVANTAGE = 100.\n",
    "team_elos = {}\n",
    "team_stats = {}\n",
    "team_ratings = {}\n",
    "X = []\n",
    "y = []\n",
    "submission_data = []\n",
    "def initialize_data():\n",
    "    for i in range(2003, prediction_year+1):\n",
    "        team_elos[i] = {}\n",
    "        team_stats[i] = {}\n",
    "        team_ratings[i] = {}\n",
    "initialize_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define Helper Functions\n",
    "def get_elo(season, team):\n",
    "    try:\n",
    "        return team_elos[season][team]\n",
    "    except:\n",
    "        try:\n",
    "            # Get the previous season's ending value.\n",
    "            team_elos[season][team] = team_elos[season-1][team]\n",
    "            return team_elos[season][team]\n",
    "        except:\n",
    "            # Get the starter elo.\n",
    "            team_elos[season][team] = base_elo\n",
    "            return team_elos[season][team]\n",
    "        \n",
    "def calc_elo(win_team, lose_team, season):\n",
    "    winner_rank = get_elo(season, win_team)\n",
    "    loser_rank = get_elo(season, lose_team)\n",
    "    rank_diff = winner_rank - loser_rank\n",
    "    exp = (rank_diff * -1) / 400\n",
    "    odds = 1 / (1 + math.pow(10, exp))\n",
    "    k = 20\n",
    "    new_winner_rank = round(winner_rank + (k * (1 - odds)))\n",
    "    new_rank_diff = new_winner_rank - winner_rank\n",
    "    new_loser_rank = loser_rank - new_rank_diff\n",
    "    return new_winner_rank, new_loser_rank\n",
    "\n",
    "def get_stat(season, team, field):\n",
    "    try:\n",
    "        stat_results = team_stats[season][team][field]\n",
    "        return sum(stat_results) / float(len(stat_results))\n",
    "    except:\n",
    "        return 0\n",
    "    \n",
    "def get_rating(season, team, day, rating):\n",
    "    try:\n",
    "        stat_results = team_ratings[season][team][rating]\n",
    "        stat_day, stat_ranking = tuple([int(x) for x in stat_result.split('-')])\n",
    "        if ((day > 0) and ((day - stat_day) >= 7)):\n",
    "            # Need to update\n",
    "            new_stat_result = ratings[(ratings['Season'] == season) & (ratings['TeamID'] == team) & (ratings['RankingDayNum'] <= day)].tail(1)\n",
    "            update_rating(season, team, day, rating, new_stat_result['OrdinalRank'].values[0])\n",
    "            return ranking\n",
    "        return stat_ranking\n",
    "    except:\n",
    "        stat_result = ratings[(ratings['Season'] == season) & (ratings['TeamID'] == team) & (ratings['RankingDayNum'] <= day)].tail(1)\n",
    "        if stat_result.shape[0] > 0:\n",
    "            ranking = stat_result['OrdinalRank'].values[0]\n",
    "            update_rating(season, team, day, rating, ranking)\n",
    "            return ranking\n",
    "        return 0\n",
    "    \n",
    "def update_rating(season, team, day, rating, ranking):\n",
    "    if team not in team_ratings[season]:\n",
    "        team_ratings[season][team] = {}\n",
    "    team_ratings[season][team][rating] = str(day) + '-' + str(rating)\n",
    "    \n",
    "def update_stats(season, team, fields):\n",
    "    if team not in team_stats[season]:\n",
    "        team_stats[season][team] = {}\n",
    "    for key, value in fields.items():\n",
    "        # Make sure we have the field.\n",
    "        if key not in team_stats[season][team]:\n",
    "            team_stats[season][team][key] = []\n",
    "        if len(team_stats[season][team][key]) >= 9:\n",
    "            team_stats[season][team][key].pop()\n",
    "        team_stats[season][team][key].append(value)\n",
    "        \n",
    "def build_test_feature(team_1, team_2, model, season, stat_fields, stat_ratings):\n",
    "    features = []\n",
    "    # Team 1\n",
    "    features.append(get_elo(season, team_1))\n",
    "    for stat in stat_fields:\n",
    "        features.append(get_stat(season, team_1, stat))\n",
    "    for rating in stat_ratings:\n",
    "        features.append(get_rating(season, team_1, 0, rating))\n",
    "    # Team 2\n",
    "    features.append(get_elo(season, team_2))\n",
    "    for stat in stat_fields:\n",
    "        features.append(get_stat(season, team_2, stat))\n",
    "    for rating in stat_ratings:\n",
    "        features.append(get_rating(season, team_2, 0, rating))\n",
    "    return features\n",
    "#     model_prediction = model.predict_proba([features])\n",
    "#     return np.clip(model_prediction[0][0], 0.05, 0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wfgm :  field goals made\n",
    "wfga :  field goals attempted\n",
    "wfgm3 :  three pointers made\n",
    "wfga3 :  three pointers attempted\n",
    "wftm :  free throws made\n",
    "wfta :  free throws attempted\n",
    "wor :  offensive rebounds\n",
    "wdr :  defensive rebounds\n",
    "wast :  assists\n",
    "wto :  turnovers\n",
    "wstl :  steals\n",
    "wblk :  blocks\n",
    "wpf :  personal fouls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_season_data(all_data):\n",
    "    # Calculate the elo for every game for every team, each season.\n",
    "    # Store the elo per season so we can retrieve their end elo\n",
    "    # later in order to predict the tournaments without having to\n",
    "    # inject the prediction into this loop.\n",
    "    for index, row in all_data.iterrows():\n",
    "        # Used to skip matchups where we don't have usable stats yet.\n",
    "        skip = 0\n",
    "        # Get starter or previous elos.\n",
    "        team_1_elo = get_elo(row['Season'], row['WTeamID'])\n",
    "        team_2_elo = get_elo(row['Season'], row['LTeamID'])\n",
    "        # Add 100 to the home team (# taken from Nate Silver analysis.)\n",
    "        if row['WLoc'] == 'H':\n",
    "            team_1_elo += 100\n",
    "        elif row['WLoc'] == 'A':\n",
    "            team_2_elo += 100         \n",
    "        # We'll create some arrays to use later.\n",
    "        team_1_features = [team_1_elo]\n",
    "        team_2_features = [team_2_elo]\n",
    "        # Build arrays out of the stats we're tracking..\n",
    "        for field in stat_fields:\n",
    "            team_1_stat = get_stat(row['Season'], row['WTeamID'], field)\n",
    "            team_2_stat = get_stat(row['Season'], row['LTeamID'], field)\n",
    "            if team_1_stat is not 0 and team_2_stat is not 0:\n",
    "                team_1_features.append(team_1_stat)\n",
    "                team_2_features.append(team_2_stat)\n",
    "            else:\n",
    "                skip = 1\n",
    "        for rating in stat_ratings:\n",
    "            team_1_rating = get_rating(row['Season'], row['WTeamID'], row['DayNum'], rating)\n",
    "            team_2_rating = get_rating(row['Season'], row['LTeamID'], row['DayNum'], rating)\n",
    "            if team_1_rating is not 0 and team_2_rating is not 0:\n",
    "                team_1_features.append(team_1_rating)\n",
    "                team_2_features.append(team_2_rating)\n",
    "            else:\n",
    "                skip = 1\n",
    "        if skip == 0:  # Make sure we have stats.\n",
    "            # Randomly select left and right and 0 or 1 so we can train\n",
    "            # for multiple classes.\n",
    "            if random.random() > 0.5:\n",
    "                X.append(team_1_features + team_2_features)\n",
    "                y.append(1)\n",
    "            else:\n",
    "                X.append(team_2_features + team_1_features)\n",
    "                y.append(0)\n",
    "        # AFTER we add the current stuff to the prediction, update for\n",
    "        # next time. Order here is key so we don't fit on data from the\n",
    "        # same game we're trying to predict.\n",
    "        if row['WFTA'] != 0 and row['LFTA'] != 0:\n",
    "            stat_1_fields = {\n",
    "                'score': row['WScore'],\n",
    "                'fgp': row['WFGM'] / row['WFGA'] * 100,\n",
    "                'fga': row['WFGA'],\n",
    "                'fga3': row['WFGA3'],\n",
    "                '3pp': row['WFGM3'] / row['WFGA3'] * 100,\n",
    "                'ftp': row['WFTM'] / row['WFTA'] * 100,\n",
    "                'or': row['WOR'],\n",
    "                'dr': row['WDR'],\n",
    "                'ast': row['WAst'],\n",
    "                'to': row['WTO'],\n",
    "                'stl': row['WStl'],\n",
    "                'blk': row['WBlk'],\n",
    "                'pf': row['WPF']\n",
    "            }            \n",
    "            stat_2_fields = {\n",
    "                'score': row['LScore'],\n",
    "                'fgp': row['LFGM'] / row['LFGA'] * 100,\n",
    "                'fga': row['LFGA'],\n",
    "                'fga3': row['LFGA3'],\n",
    "                '3pp': row['LFGM3'] / row['LFGA3'] * 100,\n",
    "                'ftp': row['LFTM'] / row['LFTA'] * 100,\n",
    "                'or': row['LOR'],\n",
    "                'dr': row['LDR'],\n",
    "                'ast': row['LAst'],\n",
    "                'to': row['LTO'],\n",
    "                'stl': row['LStl'],\n",
    "                'blk': row['LBlk'],\n",
    "                'pf': row['LPF']\n",
    "            }\n",
    "            update_stats(row['Season'], row['WTeamID'], stat_1_fields)\n",
    "            update_stats(row['Season'], row['LTeamID'], stat_2_fields)\n",
    "        # Now that we've added them, calc the new elo.\n",
    "        new_winner_rank, new_loser_rank = calc_elo(\n",
    "            row['WTeamID'], row['LTeamID'], row['Season'])\n",
    "        team_elos[row['Season']][row['WTeamID']] = new_winner_rank\n",
    "        team_elos[row['Season']][row['LTeamID']] = new_loser_rank\n",
    "    return X, y\n",
    "X, y = build_season_data(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, y_train = shuffle(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best log_loss: -0.5284, with best C: 0.001\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "params = {'C': np.logspace(start=-5, stop=3, num=9)}\n",
    "clf = GridSearchCV(logreg, params, scoring='neg_log_loss', refit=True)\n",
    "clf.fit(X_train, y_train)\n",
    "print('Best log_loss: {:.4}, with best C: {}'.format(clf.best_score_, clf.best_params_['C']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sample_sub = pd.read_csv('./SampleSubmissionStage1.csv')\n",
    "n_test_games = len(df_sample_sub)\n",
    "\n",
    "def get_year_t1_t2(ID):\n",
    "    \"\"\"Return a tuple with ints `year`, `team1` and `team2`.\"\"\"\n",
    "    return (int(x) for x in ID.split('_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test = []\n",
    "for ii, row in df_sample_sub.iterrows():\n",
    "    year, team_1, team_2 = get_year_t1_t2(row.ID)\n",
    "    feature = build_test_feature(team_1, team_2, clf, year, stat_fields, stat_ratings)\n",
    "    X_test.append(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = clf.predict_proba(X_test)[:,1]\n",
    "clipped_preds = np.clip(predictions, 0.05, 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014_1107_1110</td>\n",
       "      <td>0.489155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014_1107_1112</td>\n",
       "      <td>0.110207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014_1107_1113</td>\n",
       "      <td>0.229124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014_1107_1124</td>\n",
       "      <td>0.155952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014_1107_1140</td>\n",
       "      <td>0.243963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID      Pred\n",
       "0  2014_1107_1110  0.489155\n",
       "1  2014_1107_1112  0.110207\n",
       "2  2014_1107_1113  0.229124\n",
       "3  2014_1107_1124  0.155952\n",
       "4  2014_1107_1140  0.243963"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample_sub.Pred = clipped_preds\n",
    "df_sample_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sample_sub.to_csv('SubmissionStage1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sample_sub = pd.read_csv('./SampleSubmissionStage2.csv')\n",
    "n_test_games = len(df_sample_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = []\n",
    "for ii, row in df_sample_sub.iterrows():\n",
    "    year, team_1, team_2 = get_year_t1_t2(row.ID)\n",
    "    feature = build_test_feature(team_1, team_2, clf, year, stat_fields, stat_ratings)\n",
    "    X_test.append(feature)\n",
    "predictions = clf.predict_proba(X_test)[:,1]\n",
    "clipped_preds = np.clip(predictions, 0.05, 0.95)\n",
    "df_sample_sub.Pred = clipped_preds\n",
    "df_sample_sub.head()\n",
    "df_sample_sub.to_csv('SubmissionStage2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Kaggle NCAA",
   "language": "python",
   "name": "kaggle-ncaa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
